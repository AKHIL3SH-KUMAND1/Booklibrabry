{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dbbc023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gauthammallipeddi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "import sys\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "import PyPDF2,urllib.request,nltk,textract\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "import pdfplumber\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a966e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf=pdfplumber.open('CSE.pdf')\n",
    "pdfFileObj = open('CSE.pdf', 'rb') \n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
    "punctuations=[\"(\",\")\",\".\",\",\",\"[\",\"]\",\"-\",\":\",\";\",\"’\"]  \n",
    "text=\"\"\n",
    "for i in range(0,pdfReader.numPages):\n",
    "    page=pdf.pages[i]\n",
    "    text+=(page.extract_text())\n",
    "    text=text.lower()\n",
    "list_id = [i.start() for i in re.finditer(\"unit-\", text)]\n",
    "units=[]\n",
    "for x in range(0,len(list_id)-1):\n",
    "    start=list_id[x]\n",
    "    end=list_id[x+1]\n",
    "    units.append(text[start:end])\n",
    "units.append(text[list_id[x]:int(len(text))])\n",
    "\n",
    "\n",
    "subjects=[[]]\n",
    "j=6\n",
    "i=0\n",
    "while(j<len(units)):\n",
    "    subjects.append(units[i:j])\n",
    "    i=j\n",
    "    j=j+6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47910422",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalsub=subjects[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc50a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(finalsub[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb03e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in finalsub:\n",
    "    id=sub[5].find(\"text books\")\n",
    "    temp=sub[5][:id]\n",
    "    sub[5]=temp\n",
    "    i=i+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db8fd10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in finalsub:\n",
    "       for un in sub:\n",
    "            un=un.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc340125",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagefirst=pdf.pages[0]\n",
    "page0=pagefirst.extract_text()\n",
    "page0=page0.lower()\n",
    "tokens=word_tokenize(page0)\n",
    "stop_words=stopwords.words('english')\n",
    "keywordspage0=[word for word in tokens if not word in stop_words and not word in punctuations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69655fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "subcode_list=list()\n",
    "check=['19bs1mt01','19BS1PH02','19ES1CS01','19ES1EE01','19ES3ME02','19BS1MT04','19BS1MT05','19BS1CH01']\n",
    "for i in range(0,len(check)):\n",
    "    check[i]=check[i].lower()\n",
    "for idx,token in enumerate(tokens):\n",
    "    if(token.startswith(tuple(check))and idx<(len(tokens)-1)):\n",
    "        name=token\n",
    "        subcode_list.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd3eb793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19bs1mt01\n",
      "19bs1ph02\n",
      "19es1cs01\n",
      "19es1ee01\n",
      "19es3me02\n",
      "19bs1mt04\n",
      "19bs1mt05\n",
      "19bs1ch01\n"
     ]
    }
   ],
   "source": [
    "dataset={}\n",
    "i=0\n",
    "for code in subcode_list:\n",
    "    print(code)\n",
    "    dataset.update({code:finalsub[i]})\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b86c6c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for  code in subcode_list:\n",
    "    temp=[]\n",
    "    for unit_temp in dataset[code]:\n",
    "        unit_temp=word_tokenize(unit_temp)\n",
    "#         temp=[word for word in unit_temp if not word in stop_words and not word in punctuations]\n",
    "        temp.append(unit_temp)\n",
    "    dataset[code]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "426ec257",
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in subcode_list:\n",
    "    tempt=[[]]\n",
    "    for item in dataset[code]:\n",
    "        temp=[word for word in item if not word in stop_words and not word in punctuations]\n",
    "        tempt.append(temp)\n",
    "    dataset[code]=tempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37549f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import pytesseract\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spellchecker import SpellChecker\n",
    "import nltk\n",
    "from nltk.metrics.distance  import edit_distance\n",
    "from nltk.corpus import stopwords\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import sys\n",
    "from pdf2image import convert_from_path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16ffba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_word_extract(open_file):\n",
    "    images = convert_from_path(open_file)\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        images[i].save('page'+ str(i) +'.jpg', 'JPEG')\n",
    "\n",
    "    lister=[]\n",
    "    answer=[]\n",
    "    for i in range(0, len(images)):\n",
    "        filename = \"page\"+str(i)+\".jpg\"\n",
    "\n",
    "        text = str(((pytesseract.image_to_string(PIL.Image.open(filename)))))\n",
    "        text = text.replace('-\\n', '')    \n",
    "\n",
    "        lister=word_tokenize(text)\n",
    "        answer=answer+lister\n",
    "\n",
    "\n",
    "    solution=[]\n",
    "    punc=[\"(\",\")\",\".\",\",\",\"[\",\"]\",\"-\",\":\",\";\",\"’\",\" \",\"\",''] \n",
    "    stop_words=stopwords.words('english')\n",
    "    solution=[word.lower() for word in answer if not word.lower() in stop_words and not word in punc]\n",
    "    \n",
    "#     import os\n",
    "#     os.remove(file) for file in os.listdir('path/to/directory') if file.endswith('.jpg')\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d0eeeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(pdfwords):\n",
    "    freq={}\n",
    "    for word in pdfwords:\n",
    "        if (word in freq):\n",
    "            freq[word] += 1\n",
    "        else:\n",
    "            freq[word] = 1\n",
    "\n",
    "    return freq\n",
    "\n",
    "def findSubAndUnit(subcodelist,data,userPdf,idf):\n",
    "    count={}\n",
    "    \n",
    "    for code in subcodelist:\n",
    "        unitNumber=0\n",
    "        listOfPair=[[]]\n",
    "        for unit in data[code]:\n",
    "            freq=0\n",
    "            for word in unit:\n",
    "                if word in userPdf:\n",
    "                    freq=freq+idf[word]\n",
    "            tl=[unitNumber,freq]\n",
    "            listOfPair.append(tl)\n",
    "            unitNumber=unitNumber+1\n",
    "        count[code]=listOfPair\n",
    "    codereq=[]\n",
    "    unitreq=0\n",
    "    maxFreq=0\n",
    "    for key in count:\n",
    "        for i in range(0,len(count[key])):\n",
    "            j=1\n",
    "            tu=1\n",
    "            for val in count[key][i]:\n",
    "                if(j==1):\n",
    "                    tu=val\n",
    "                if(j==2):\n",
    "                    if val>maxFreq:\n",
    "                        maxFreq=val\n",
    "                        codereq=key\n",
    "                        unitreq=tu\n",
    "                j=j+1\n",
    "    rli=[]\n",
    "    rli.append(codereq)\n",
    "    rli.append(unitreq)\n",
    "    return rli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03a1341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindSubName(code):\n",
    "    sdict={'19bs1mt01':'Calculus for Engineers','19bs1ph02':'Engineering Physics','19es1cs01':'Programming through C','19es1ee01':'Basics of Electrical Energy for Engineers','19es3me02':'Engineering Drawing','19bs1mt04':'Linear Algebra and Advanced Calculus','19bs1mt05':'Statistical Methods for Data Analysis','19bs1ch01':'Engineering Chemistry'}\n",
    "    return sdict[code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b77fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "def path_move(open_file,direct):\n",
    "    directory=direct\n",
    "    parent_direct= '/Users/gauthammallipeddi/Docs/College/'\n",
    "    try:\n",
    "        path=os.path.join(parent_direct,directory)\n",
    "        os.mkdir(path)\n",
    "        print(\"Directory Created\")\n",
    "    except:\n",
    "        pass\n",
    "    source=open_file\n",
    "    destination=path\n",
    "    shutil.move(source,destination)\n",
    "    print(\"File Moved\")\n",
    "    return destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d562a463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['19bs1ph02', 1]\n",
      "Engineering Physics\n",
      "Directory Created\n",
      "File Moved\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "import PyPDF2\n",
    "from tkinter import filedialog\n",
    "import cv2 \n",
    "import pytesseract\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spellchecker import SpellChecker\n",
    "import nltk\n",
    "from nltk.metrics.distance  import edit_distance\n",
    "from nltk.corpus import stopwords\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import sys\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "import PIL.Image\n",
    "import subprocess\n",
    "import shlex\n",
    "\n",
    "root = Tk()\n",
    "root.title(\"PDF Reader!!\")\n",
    "root.geometry(\"200x200\")\n",
    "\n",
    "def clear_text_box():\n",
    "    my_text.delete(1.0,END)\n",
    "    \n",
    "def open_pdf():\n",
    "    open_file = filedialog.askopenfilename(\n",
    "        initialdir=\"/Users/gauthammallipeddi/Docs/College/II-I/DBMS/\",\n",
    "        title = \"Open PDF file\",\n",
    "        filetypes = (\n",
    "        (\"PDF Files\",\"*.pdf\"),\n",
    "        (\"All Files\",\".\")))\n",
    "    if open_file:\n",
    "        page_stuff = pdf_word_extract(open_file)\n",
    "        mydict=idf(page_stuff)\n",
    "        Ans=findSubAndUnit(subcode_list,dataset,page_stuff,mydict)\n",
    "        print(Ans)\n",
    "        SubCode=Ans[0]\n",
    "        Subject = FindSubName(SubCode)\n",
    "        print(Subject)\n",
    "        to_move = path_move(open_file,Subject)\n",
    "        my_label.config(text=to_move)\n",
    "        os.system(\"open\"+shlex.quote(to_move))\n",
    "\n",
    "my_button=Button(root,text=\"OPEN\",command=open_pdf)\n",
    "my_button.pack(pady=20)\n",
    "my_label=Label(root,text=\" \")\n",
    "my_label.pack(pady=20)\n",
    "\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d212a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
